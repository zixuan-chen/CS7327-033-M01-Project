{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empirical-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "effective-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data_hw2/train_data.npy')\n",
    "label = np.load(\"data_hw2/train_label.npy\")\n",
    "c = np.arange(len(data))\n",
    "np.random.shuffle(c)\n",
    "data, label = data[c], label[c]\n",
    "n = data.shape[0]\n",
    "split = int(0.8*n)\n",
    "train_data = data[:split]\n",
    "train_label = label[:split]\n",
    "val_data = data[split:]\n",
    "val_label = label[split:]\n",
    "test_data = np.load(\"data_hw2/test_data.npy\")\n",
    "test_label = np.load(\"data_hw2/test_label.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6671653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vs_rest(category):\n",
    "    train_label_new = np.where(train_label == category, 1, 0)\n",
    "    val_label_new = np.where(val_label == category, 1, 0)\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                       SVC(kernel='linear', probability=True))\n",
    "    clf.fit(train_data, train_label_new)\n",
    "    acc = clf.score(val_data, val_label_new)\n",
    "    print(\"validation accuracy: %f\" % acc)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d654aa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "clf1 = train_one_vs_rest(-1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ccacc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "clf2 = train_one_vs_rest(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d8c1249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "clf3 = train_one_vs_rest(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7cc9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = clf1.predict_proba(test_data)[:, 1]\n",
    "prob2 = clf2.predict_proba(test_data)[:, 1]\n",
    "prob3 = clf3.predict_proba(test_data)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ed8f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: %f 0.48829849867530173\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.vstack((prob1, prob2, prob3))\n",
    "test_pred = np.argmax(test_pred, axis=0)\n",
    "test_pred = np.where(test_pred == 0, -1, test_pred)\n",
    "test_pred = np.where(test_pred == 1, 0, test_pred)\n",
    "test_pred = np.where(test_pred == 2, 1, test_pred)\n",
    "accuracy = np.sum(test_pred == test_label) / len(test_label)\n",
    "print(\"final accuracy: %f\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f289e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desicison = 6273\n",
      "prob1 =  6267\n",
      "accuracy =  0.9995584339122755\n"
     ]
    }
   ],
   "source": [
    "decision = clf1.decision_function(test_data)\n",
    "decision = np.where(decision > 0, 1, 0)\n",
    "prob1 = clf1.predict_proba(test_data)[:, 1]\n",
    "prob1 = np.where(prob1 >= 0.5, 1, 0)\n",
    "print(\"desicison =\", decision.sum())\n",
    "print(\"prob1 = \", prob1.sum())\n",
    "acc = (decision == prob1).sum() / len(decision)\n",
    "print(\"accuracy = \", acc)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
